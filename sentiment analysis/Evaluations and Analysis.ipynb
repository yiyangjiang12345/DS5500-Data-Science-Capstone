{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aab2817",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('sentiment_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43c280ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[31143     0     0     0  5564]\n",
      " [ 4248 17193     0     0     0]\n",
      " [    0  2266 21701     0     0]\n",
      " [    0     0  2988 31139     0]\n",
      " [    0     0     0  4293 40788]]\n",
      "\n",
      "Accuracy: 0.8799985123014077\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.88      0.85      0.86     36707\n",
      "           2       0.88      0.80      0.84     21441\n",
      "           3       0.88      0.91      0.89     23967\n",
      "           4       0.88      0.91      0.90     34127\n",
      "           5       0.88      0.90      0.89     45081\n",
      "\n",
      "    accuracy                           0.88    161323\n",
      "   macro avg       0.88      0.87      0.88    161323\n",
      "weighted avg       0.88      0.88      0.88    161323\n",
      "\n",
      "\n",
      "Cohen's Kappa: 0.8470463425025325\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    "\n",
    "# These are the true sentiment scores calculate based on voteed_up, votes_up, votes_funny and weighted_vote_score\n",
    "true_scores = df['true_scores']\n",
    "\n",
    "# These are the sentiment scores predicted by your BERT model\n",
    "predicted_scores = df['sentiment_score']\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(true_scores, predicted_scores)\n",
    "\n",
    "# Calculate the accuracy of the predictions\n",
    "accuracy = accuracy_score(true_scores, predicted_scores)\n",
    "\n",
    "# Generate a classification report\n",
    "class_report = classification_report(true_scores, predicted_scores)\n",
    "\n",
    "# Calculate Cohen's Kappa\n",
    "kappa_score = cohen_kappa_score(true_scores, predicted_scores)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nAccuracy:\", accuracy)\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n",
    "print(\"\\nCohen's Kappa:\", kappa_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053f4dac",
   "metadata": {},
   "source": [
    "High Accuracy: The bert model achieved an accuracy of approximately 88%, which means it correctly predicted the sentiment scores for 88% of the reviews in your dataset.\n",
    "\n",
    "Balanced Performance Across Categories: The precision, recall, and F1-scores are consistently high across all sentiment categories (1 to 5), suggesting that the model is reliably identifying the sentiment of the reviews across the spectrum, without significant bias toward any specific sentiment score.\n",
    "\n",
    "Confusion Matrix Insights: Most errors seem to occur between adjacent sentiment categories, which is common in sentiment analysis due to the subjective nature of sentiment.\n",
    "\n",
    "Strong Agreement (Cohen's Kappa): The Cohen's Kappa score of 0.847 indicates a strong agreement between the modelâ€™s predictions and the actual sentiment scores, suggesting that the model's assessments are consistent with the expected outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0bb26e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
